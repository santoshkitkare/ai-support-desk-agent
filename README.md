# AI Support Desk Agent (LLM Powered Customer Support Automation)

### ğŸš€ Overview
The AI Support Desk Agent reduces customer support workload by providing instant, context-aware responses using company knowledge base documents (PDF, DOCX, CSV, FAQ pages).  
It acts as a first-line support system and can escalate to a human agent when required.

### ğŸ’¡ Key Features
- GPT/Claude powered conversational AI
- Upload internal documents as knowledge base
- Vector search using FAISS for context-aware answers
- Fallback "Escalate to Human" mode
- Chat history & memory retention
- API-first design â€” can be plugged into websites, CRMs, or support platforms

### ğŸ§  Tech Stack
| Layer | Technology |
|-------|------------|
| Backend | FastAPI |
| LLM | GPT / Claude |
| Embeddings | OpenAI / SentenceTransformers |
| Vector DB | FAISS |
| Deployment | AWS (ECS / EC2) + Docker |

### ğŸ— Architecture
```
Client â†’ Streamlit UI â† Upload docs / Chat / Dashboard
      â†“
      â†“  REST API
      â†“
FastAPI Backend
      â†“
      â†“
Embedding Engine
      â†“
      â†“
FAISS Index
      â†“
      â†“
Knowledge Base (PDF/CSV/DOCX)
      â†“
      â†“
      â†“
Conversation DB <-- For chat history & analytics
```

### ğŸš€ Features

| Module                             | Status |
| ---------------------------------- | ------ |
| Document upload (PDF/DOCX/CSV/TXT) | âœ…     |
| Text extraction & chunking         | âœ…     |
| HuggingFace embeddings             | âœ…     |
| FAISS similarity search            | âœ…     |
| LLM answer generation (OpenAI)     | âœ…     |
| Conversation history               | âœ…     |
| Analytics dashboard                | âœ…     |
| Escalation to human flag           | ğŸ”œ     |
| Auth / Multi-tenant SaaS           | ğŸ”œ     |


### ğŸ§° Tech Stack

| Layer              | Tech                                 |
| ------------------ | ------------------------------------ |
| Frontend           | Streamlit                            |
| Backend            | FastAPI                              |
| LLM                | OpenAI + HuggingFace embeddings      |
| Vector DB          | FAISS                                |
| Persistence        | SQLite / PostgreSQL (both supported) |
| Containerization   | Docker (optional)                    |
| Deployment options | AWS EC2 / Streamlit Cloud / Dockers  |


### ğŸ“‚ Project Structure
```
ai-support-agent/
â”£ app/
â”ƒ â”£ routers/
â”ƒ â”£ services/
â”ƒ â”£ utils/
â”ƒ â”— main.py
â”£ data/
â”£ Dockerfile
â”£ requirements.txt
â”— README.md
```


### ğŸ“Œ How It Works
1. User uploads company documents
2. Documents are chunked + converted to embeddings
3. User enters a support query
4. System searches FAISS for relevant context
5. GPT/Claude generates an accurate, cited answer

### ğŸ§ª Sample Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/upload-docs/` | Upload support knowledge base |
| POST | `/chat/` | Chat with support agent |
| GET | `/history/` | Retrieve conversation history |

### ğŸš€ Deployment
docker build -t ai-support-agent .
docker run -p 8000:8000 ai-support-agent

For AWS deployment: ECS + Load Balancer + ECR + CloudWatch.
---

### ğŸ¤ Ideal Use Cases
- Customer support automation
- HR / IT helpdesk
- SaaS in-product support agents
- Enterprise documentation Q&A

âš™ï¸ Local Setup
1ï¸âƒ£ Clone the repository
```
git clone https://github.com/<your_user>/ai-support-desk-agent.git
cd ai-support-desk-agent
```
2ï¸âƒ£ Create virtual environment
```
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```
3ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```

4ï¸âƒ£ Add environment variables
Create .env in project root:
```
OPENAI_API_KEY=xxxxxxxxxxxx
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```
5ï¸âƒ£ Start the backend
```
uvicorn app.main:app --reload
```

6ï¸âƒ£ Start the UI
```
streamlit run frontend/app.py
```
### ğŸ§ª API Reference
| Method | Endpoint                      | Description                                     |
| ------ | ----------------------------- | ----------------------------------------------- |
| `POST` | `/docs/upload`                | Upload and index documents                      |
| `POST` | `/chat`                       | LLM chat with RAG                               |
| `GET`  | `/analytics/summary`          | Stats: conversations / escalations / resolution |
| `GET`  | `/analytics/trending-queries` | Last 5 queries                                  |

### Open Swagger docs:
```
http://localhost:8000/docs
```

### ğŸ¤ Contributing

PRs and feature requests are welcome. Feel free to fork the repo and improve it.

### â­ Future Enhancements (roadmap)
* Slack / Email escalation when LLM flags â€œescalate_to_humanâ€
* Authentication + multi-tenant support
* Admin panel for knowledge-base management
* Billing tiers for SaaS customers

### ğŸ“„ License
MIT â€” free to use and modify.

### ğŸ§‘â€ğŸ’» Author
Built with â¤ï¸ by Santosh Itkare

### ğŸ“© Contact
For enterprise deployment or integration requests, feel free to connect.
